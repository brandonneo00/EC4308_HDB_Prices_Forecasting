---
title: "ex4308"
author: "Chow Xin Tian, Neo Bing Jie Brandon, Wong Fang Ting"
date: "2025-04-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

load data and packages
```{r}
df_cleaned <- read.csv("../data/processed_hdb_data.csv")

library(dplyr)
library(fastDummies)
library(glmnet)
library(Metrics)
library(corrplot)

```


Prepare Data
```{r}
# ---- Prepare Data with Scaling ----
set.seed(123)

# 1. Create matrix X and target Y
X <- model.matrix(resale_price ~ . -1, data = df_cleaned)
Y <- df_cleaned$resale_price

# 2. Split into training and test sets
n <- nrow(X)
train_idx <- sample(1:n, size = 0.8 * n)
X_train <- X[train_idx, ]
Y_train <- Y[train_idx]
X_test  <- X[-train_idx, ]
Y_test  <- Y[-train_idx]

# 3. Compute min and max for each feature in training set
x_mins <- apply(X_train, 2, min)
x_maxs <- apply(X_train, 2, max)

# 4. Scale training data to [0,1]
X_train_scaled <- scale(X_train, center = x_mins, scale = x_maxs - x_mins)

# 5. Scale test data using training min and max
X_test_scaled <- scale(X_test, center = x_mins, scale = x_maxs - x_mins)

# 6. RÂ² helper
rsq <- function(actual, predicted) {
  1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
}

```

OLS Baseline
```{r}
# Convert scaled matrices to data frames
df_train_scaled <- as.data.frame(X_train_scaled)
df_train_scaled$resale_price <- Y_train

df_test_scaled <- as.data.frame(X_test_scaled)
df_test_scaled$resale_price <- Y_test  # for evaluation only

# Fit OLS model using scaled training data
ols_model <- lm(resale_price ~ ., data = df_train_scaled)

# Predict on scaled test data
ols_preds <- predict(ols_model, newdata = df_test_scaled)

# Compute out-of-sample metrics
results_oos <- data.frame(
  Model = "OLS (Baseline)",
  RMSE  = round(rmse(Y_test, ols_preds), 5),
  MAE   = round(mae(Y_test, ols_preds), 5),
  MAPE  = round(mape(Y_test, ols_preds) * 100, 5),
  R2    = round(rsq(Y_test, ols_preds), 5)
)

# View results
print(results_oos)

```

Lasso, Ridge, Elastic Net
```{r}
# ---- Lambda grid ----
lambda_grid <- 10^seq(10, -2, length = 100)

# ---- CV-based Models with scaled data ----
evaluate_oos <- function(alpha_val, label) {
  cv_model <- cv.glmnet(X_train_scaled, Y_train, alpha = alpha_val, lambda = lambda_grid)
  best_lambda <- cv_model$lambda.min
  preds <- predict(cv_model, newx = X_test_scaled, s = best_lambda)

  rmse_val <- rmse(Y_test, preds)
  mae_val  <- mae(Y_test, preds)
  mape_val <- mape(Y_test, preds) * 100
  r2_val   <- rsq(Y_test, preds)

  return(data.frame(
    Model = label,
    RMSE  = round(rmse_val, 5),
    MAE   = round(mae_val, 5),
    MAPE  = round(mape_val, 5),
    R2    = round(r2_val, 5)
  ))
}

results_oos <- rbind(
  results_oos,
  evaluate_oos(1, "LASSO"),
  evaluate_oos(0, "Ridge"),
  evaluate_oos(0.5, "Elastic Net")
)

```

```{r}
# Fit LASSO model on scaled data
lasso_model <- glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)

# Cross-validated LASSO to find best lambda
cv_lasso <- cv.glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)
best_lambda_lasso <- cv_lasso$lambda.min

# Extract coefficients at best lambda
lasso_coefs <- predict(lasso_model, s = best_lambda_lasso, type = "coefficients")
lasso_coefs <- as.matrix(lasso_coefs)

# Get feature names with zero coefficients (excluding intercept)
removed_features <- rownames(lasso_coefs)[which(lasso_coefs == 0)]
removed_features <- setdiff(removed_features, "(Intercept)")

# Display removed features
cat("LASSO removed", length(removed_features), "features:\n")
print(removed_features)

```


Post Lasso
```{r}
# ---- Post-LASSO ----
lasso_model <- glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)
cv_lasso <- cv.glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)
best_lambda_lasso <- cv_lasso$lambda.min
chosen_coef <- predict(lasso_model, s = best_lambda_lasso, type = "coefficients")
nonzero_names <- rownames(chosen_coef)[which(chosen_coef != 0)]
nonzero_names <- setdiff(nonzero_names, "(Intercept)")
nonzero_idx <- which(colnames(X_train_scaled) %in% nonzero_names)

X_train_post <- X_train_scaled[, nonzero_idx]
X_test_post  <- X_test_scaled[, nonzero_idx]
df_train_post <- data.frame(resale_price = Y_train, X_train_post)
df_test_post  <- data.frame(X_test_post)

post_lasso_model <- lm(resale_price ~ ., data = df_train_post)
preds_post_lasso <- predict(post_lasso_model, newdata = df_test_post)

results_oos <- rbind(
  results_oos,
  data.frame(
    Model = "Post-LASSO",
    RMSE  = round(rmse(Y_test, preds_post_lasso), 5),
    MAE   = round(mae(Y_test, preds_post_lasso), 5),
    MAPE  = round(mape(Y_test, preds_post_lasso) * 100, 5),
    R2    = round(rsq(Y_test, preds_post_lasso), 5)
  )
)

```

Elastic Net (best alpha)
```{r}
# ---- Elastic Net with best alpha ----
alpha_grid <- seq(0.1, 0.9, by = 0.1)
cv_errors <- c()
best_models <- list()
k <- 10

for (a in alpha_grid) {
  cv_model <- cv.glmnet(X_train_scaled, Y_train, alpha = a, lambda = lambda_grid, nfolds = k)
  cv_errors <- c(cv_errors, min(cv_model$cvm))
  best_models[[as.character(a)]] <- cv_model
}

best_alpha <- alpha_grid[which.min(cv_errors)]
best_elastic_model <- best_models[[as.character(best_alpha)]]
best_lambda_elastic <- best_elastic_model$lambda.min
preds_elastic <- predict(best_elastic_model, newx = X_test_scaled, s = best_lambda_elastic)

results_oos <- rbind(
  results_oos,
  data.frame(
    Model = paste0("Elastic Net (Î±=", best_alpha, ")"),
    RMSE  = round(rmse(Y_test, preds_elastic), 5),
    MAE   = round(mae(Y_test, preds_elastic), 5),
    MAPE  = round(mape(Y_test, preds_elastic) * 100, 5),
    R2    = round(rsq(Y_test, preds_elastic), 5)
  )
)

# ---- Final results ----
print(results_oos)

```


```{r}
# --- OLS Coefficients ---
ols_model <- lm(resale_price ~ ., data = df_train_scaled)  # scaled # Ensure OLS and Ridge coefficients have matching names
ols_coefs <- coef(ols_model)
ols_coefs <- ols_coefs[names(ols_coefs) != "(Intercept)"]

ridge_model <- glmnet(X_train_scaled, Y_train, alpha = 0, lambda = lambda_grid)
cv_ridge <- cv.glmnet(X_train_scaled, Y_train, alpha = 0, lambda = lambda_grid)
best_lambda_ridge <- cv_ridge$lambda.min
ridge_coefs <- predict(ridge_model, s = best_lambda_ridge, type = "coefficients")
ridge_coefs <- as.vector(ridge_coefs)
names(ridge_coefs) <- rownames(predict(ridge_model, s = best_lambda_ridge, type = "coefficients"))
ridge_coefs <- ridge_coefs[names(ridge_coefs) != "(Intercept)"]

# Match common feature names
common_names <- intersect(names(ols_coefs), names(ridge_coefs))

# Compute absolute difference
coef_diff <- abs(ols_coefs[common_names] - ridge_coefs[common_names])

# Create sorted dataframe from largest to smallest difference
coef_comparison <- data.frame(
  Feature = common_names,
  OLS_Coefficient = round(ols_coefs[common_names], 5),
  Ridge_Coefficient = round(ridge_coefs[common_names], 5),
  Absolute_Difference = round(coef_diff, 5)
)

coef_comparison <- coef_comparison[complete.cases(coef_comparison), ]


coef_comparison_sorted <- coef_comparison[order(-coef_comparison$Absolute_Difference), ]

# Top 10 most different
top10_most_diff <- head(coef_comparison_sorted, 10)
cat("Top 10 Most Different Features:\n")
print(top10_most_diff)

# Top 10 least different
top10_least_diff <- tail(coef_comparison_sorted, 10)
cat("\nTop 10 Least Different Features:\n")
print(top10_least_diff)
```

```{r}

# === OLS FEATURE IMPORTANCE ===
ols_coefs <- coef(ols_model)
ols_coefs <- ols_coefs[names(ols_coefs) != "(Intercept)"]  # remove intercept
ols_importance <- data.frame(
  Feature = names(ols_coefs),
  Coefficient = round(ols_coefs, 5),
  Abs_Coefficient = round(abs(ols_coefs), 5)
)
# Top 10 by absolute value
top10_ols_importance <- ols_importance[order(-ols_importance$Abs_Coefficient), ][1:10, ]
cat("ðŸ”¹ Top 10 Most Important OLS Features:\n")
print(top10_ols_importance)

# === RIDGE FEATURE IMPORTANCE ===
ridge_model <- glmnet(X_train_scaled, Y_train, alpha = 0, lambda = lambda_grid)
cv_ridge <- cv.glmnet(X_train_scaled, Y_train, alpha = 0, lambda = lambda_grid)
best_lambda_ridge <- cv_ridge$lambda.min
ridge_coefs <- predict(ridge_model, s = best_lambda_ridge, type = "coefficients")
ridge_coefs <- as.vector(ridge_coefs)
names(ridge_coefs) <- rownames(predict(ridge_model, s = best_lambda_ridge, type = "coefficients"))
ridge_coefs <- ridge_coefs[names(ridge_coefs) != "(Intercept)"]
ridge_importance <- data.frame(
  Feature = names(ridge_coefs),
  Coefficient = round(ridge_coefs, 5),
  Abs_Coefficient = round(abs(ridge_coefs), 5)
)
# Top 10 by absolute value
top10_ridge_importance <- ridge_importance[order(-ridge_importance$Abs_Coefficient), ][1:10, ]
cat("\nðŸ”¹ Top 10 Most Important Ridge Features:\n")
print(top10_ridge_importance)


```
