---
title: "Ensemble_Trees"
author: "Brandon Neo Bing Jie"
date: "2025-04-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# renv::init()
```


```{r}
library(randomForest) # for random forest
library(caret) # for hyperparam tuning 
library(Metrics) # for performance metrics
```

```{r}
df_cleaned <- read.csv("../data/processed_hdb_data.csv")
```

# Prepare Data

```{r}

# ---- Prepare data ----
set.seed(123)
X <- model.matrix(resale_price ~ . -1, data = df_cleaned)
Y <- df_cleaned$resale_price
n <- nrow(X)
train_idx <- sample(1:n, size = 0.8 * n)
X_train <- X[train_idx, ]
Y_train <- Y[train_idx]
X_test <- X[-train_idx, ]
Y_test <- Y[-train_idx]

# ---- R² helper ----
rsq <- function(actual, predicted) {
  1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
}
```


```{r}
# 2.1. Prepare a single data.frame for caret
train_df <- data.frame(resale_price = Y_train, X_train)

set.seed(123)

# 2.2. Define cross‐validation strategy
ctrl <- trainControl(
  method           = "cv", # "repeatedcv"
  number           = 5,       # 5‐fold CV
  search           = "grid"
)

# 2.3. Define a tuning grid for mtry (you can also include ntree or nodesize by wrapping randomForest in a custom model)
mtry_vals <- seq( floor(sqrt(ncol(X_train))) - 5,
                  floor(sqrt(ncol(X_train))) + 5,
                  by = 2 )

grid <- expand.grid(mtry = mtry_vals)

# 2.4. Run the grid search
rf_tuned <- train(
  resale_price ~ .,
  data       = train_df,
  method     = "rf",
  metric     = "RMSE",    
  tuneGrid   = grid,
  trControl  = ctrl,
  ntree      = 500
)

# 2.5. Inspect results
print(rf_tuned)
```

```{r}
plot(rf_tuned)    # show performance vs. mtry
```


```{r}
# 3.1. Extract the best mtry
best_mtry_caret <- rf_tuned$bestTune$mtry
```



```{r}
# 3.2. Refit on full training set
new_rf_final <- randomForest(
  x     = X_train,
  y     = Y_train,
  mtry  = best_mtry_caret,
  ntree = 500          # increase if you want more stability, set 1000
)

# 3.3. Predict and compute R² on the test set
new_preds <- predict(new_rf_final, X_test)

new_rf_results = data.frame(
  Model = "Random Forest",
  RMSE = round(rmse(Y_test, new_preds), 5),
  MAE  = round(mae(Y_test, new_preds), 5),
  MAPE = round(mape(Y_test, new_preds) * 100, 5),
  R2   = round(rsq(Y_test, new_preds), 5)
)

print(new_rf_results)

```


```{r}
new_rf_preds_df <- data.frame(RF_predictions = new_preds)  # Custom column name
write.csv(new_rf_preds_df, "../results/random_forest_oos_predictions.csv", row.names = FALSE)

```


```{r}
varImpPlot(new_rf_final, 
           sort   = TRUE,      # sort by importance
           n.var  = 10,        # top 20 variables
           type = 2,
           main   = "RF Variable Importance"
)
```