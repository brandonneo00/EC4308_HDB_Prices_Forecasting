---
title: "ex4308"
author: "Chow Xin Tian, Neo Bing Jie Brandon, Wong Fang Ting"
date: "2025-04-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

load data and packages
```{r}
#df_cleaned <- read.csv("../data/processed_hdb_data.csv")
df_cleaned <- processed_hdb_data
library(dplyr)
library(fastDummies)
library(glmnet)
library(Metrics)
library(corrplot)
library(car)
library(ggplot2)


```


Prepare Data
```{r}
# ---- Prepare Data with Scaling ----
set.seed(123)

# 1. Create matrix X and target Y
X <- model.matrix(resale_price ~ . -1, data = df_cleaned)
Y <- df_cleaned$resale_price

# 2. Split into training and test sets
n <- nrow(X)
train_idx <- sample(1:n, size = 0.8 * n)
X_train <- X[train_idx, ]
Y_train <- Y[train_idx]
X_test  <- X[-train_idx, ]
Y_test  <- Y[-train_idx]

# 3. Compute min and max for each feature in training set
x_mins <- apply(X_train, 2, min)
x_maxs <- apply(X_train, 2, max)

# 4. Scale training data to [0,1]
X_train_scaled <- scale(X_train, center = x_mins, scale = x_maxs - x_mins)

# 5. Scale test data using training min and max
X_test_scaled <- scale(X_test, center = x_mins, scale = x_maxs - x_mins)

# 6. R² helper
rsq <- function(actual, predicted) {
  1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
}

```

OLS Baseline
```{r}
# Convert scaled matrices to data frames
df_train_scaled <- as.data.frame(X_train_scaled)
df_train_scaled$resale_price <- Y_train

df_test_scaled <- as.data.frame(X_test_scaled)
df_test_scaled$resale_price <- Y_test  # for evaluation only

# Fit OLS model using scaled training data
ols_model <- lm(resale_price ~ ., data = df_train_scaled)



# Predict on scaled test data
ols_preds <- predict(ols_model, newdata = df_test_scaled)

# Compute out-of-sample metrics
results_oos <- data.frame(
  Model = "OLS (Baseline)",
  RMSE  = round(rmse(Y_test, ols_preds), 5),
  MAE   = round(mae(Y_test, ols_preds), 5),
  MAPE  = round(mape(Y_test, ols_preds) * 100, 5),
  R2    = round(rsq(Y_test, ols_preds), 5)
)

# View results
print(results_oos)

## combine predictions and actual values
ols_results_df <- data.frame(
  Actual = Y_test,
  Predicted = ols_preds
)

## save to csv
write.csv(ols_results_df, "ols_preds.csv", row.names = FALSE)

```


```{r}
# === Plot: Actual vs Predicted ===
# Optionally sample a subset
set.seed(42)
ols_sample <- ols_results_df[sample(nrow(ols_results_df), 5000), ]

ggplot(ols_sample, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.2, color = "blue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "OLS: Actual vs Predicted Resale Prices",
       x = "Actual Price", y = "Predicted Price") +
  theme_minimal()

#ggsave("ols_actual_vs_predicted.png", width = 8, height = 6, dpi = 300)

```


Lasso, Ridge, Elastic Net
```{r}
# ---- Lambda grid ----
lambda_grid <- 10^seq(10, -2, length = 100)

# ---- CV-based Models with scaled data ----
evaluate_oos <- function(alpha_val, label) {
  cv_model <- cv.glmnet(X_train_scaled, Y_train, alpha = alpha_val, lambda = lambda_grid)
  best_lambda <- cv_model$lambda.min
  preds <- predict(cv_model, newx = X_test_scaled, s = best_lambda)

  rmse_val <- rmse(Y_test, preds)
  mae_val  <- mae(Y_test, preds)
  mape_val <- mape(Y_test, preds) * 100
  r2_val   <- rsq(Y_test, preds)

  return(data.frame(
    Model = label,
    RMSE  = round(rmse_val, 5),
    MAE   = round(mae_val, 5),
    MAPE  = round(mape_val, 5),
    R2    = round(r2_val, 5)
  ))
}

results_oos <- rbind(
  results_oos,
  evaluate_oos(1, "LASSO"),
  evaluate_oos(0, "Ridge"),
  evaluate_oos(0.5, "Elastic Net")
)

## Ridge OOS Preds
ridge_model <- cv.glmnet(X_train_scaled, Y_train, alpha = 0, lambda = lambda_grid)
ridge_best_lambda <- ridge_model$lambda.min
ridge_preds <- predict(ridge_model, newx = X_test_scaled, s = ridge_best_lambda)

## saving acutal and preds into csv
ridge_results_df <- data.frame(
  Actual = Y_test,
  Predicted = as.numeric(ridge_preds)
)

write.csv(ridge_results_df, "ridge_preds.csv", row.names = FALSE)


```

```{r}
# Fit LASSO model on scaled data
lasso_model <- glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)

# Cross-validated LASSO to find best lambda
cv_lasso <- cv.glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)
best_lambda_lasso <- cv_lasso$lambda.min

# Extract coefficients at best lambda
lasso_coefs <- predict(lasso_model, s = best_lambda_lasso, type = "coefficients")
lasso_coefs <- as.matrix(lasso_coefs)

# Get feature names with zero coefficients (excluding intercept)
removed_features <- rownames(lasso_coefs)[which(lasso_coefs == 0)]
removed_features <- setdiff(removed_features, "(Intercept)")

# Display removed features
cat("LASSO removed", length(removed_features), "features:\n")
print(removed_features)

```


Post Lasso
```{r}
# ---- Post-LASSO ----
lasso_model <- glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)
cv_lasso <- cv.glmnet(X_train_scaled, Y_train, alpha = 1, lambda = lambda_grid)
best_lambda_lasso <- cv_lasso$lambda.min
chosen_coef <- predict(lasso_model, s = best_lambda_lasso, type = "coefficients")
nonzero_names <- rownames(chosen_coef)[which(chosen_coef != 0)]
nonzero_names <- setdiff(nonzero_names, "(Intercept)")
nonzero_idx <- which(colnames(X_train_scaled) %in% nonzero_names)

X_train_post <- X_train_scaled[, nonzero_idx]
X_test_post  <- X_test_scaled[, nonzero_idx]
df_train_post <- data.frame(resale_price = Y_train, X_train_post)
df_test_post  <- data.frame(X_test_post)

post_lasso_model <- lm(resale_price ~ ., data = df_train_post)
preds_post_lasso <- predict(post_lasso_model, newdata = df_test_post)

results_oos <- rbind(
  results_oos,
  data.frame(
    Model = "Post-LASSO",
    RMSE  = round(rmse(Y_test, preds_post_lasso), 5),
    MAE   = round(mae(Y_test, preds_post_lasso), 5),
    MAPE  = round(mape(Y_test, preds_post_lasso) * 100, 5),
    R2    = round(rsq(Y_test, preds_post_lasso), 5)
  )
)

```

Elastic Net (best alpha)
```{r}
# ---- Elastic Net with best alpha ----
alpha_grid <- seq(0.1, 0.9, by = 0.1)
cv_errors <- c()
best_models <- list()
k <- 10

for (a in alpha_grid) {
  cv_model <- cv.glmnet(X_train_scaled, Y_train, alpha = a, lambda = lambda_grid, nfolds = k)
  cv_errors <- c(cv_errors, min(cv_model$cvm))
  best_models[[as.character(a)]] <- cv_model
}

best_alpha <- alpha_grid[which.min(cv_errors)]
best_elastic_model <- best_models[[as.character(best_alpha)]]
best_lambda_elastic <- best_elastic_model$lambda.min
preds_elastic <- predict(best_elastic_model, newx = X_test_scaled, s = best_lambda_elastic)

results_oos <- rbind(
  results_oos,
  data.frame(
    Model = paste0("Elastic Net (α=", best_alpha, ")"),
    RMSE  = round(rmse(Y_test, preds_elastic), 5),
    MAE   = round(mae(Y_test, preds_elastic), 5),
    MAPE  = round(mape(Y_test, preds_elastic) * 100, 5),
    R2    = round(rsq(Y_test, preds_elastic), 5)
  )
)

# ---- Final results ----
print(results_oos)

```

Plots for Random Forest
```{r}
rf_oos_new = new_random_forest_oos_predictions

set.seed(42)  # for reproducibility


rf_oos_new$Actual <- Y_test
rf_oos_new$Predicted <- rf_oos_new$RF_predictions

## sample 5000 rows
rf_sample <- rf_oos_new[sample(nrow(rf_oos_new), 5000), ]

## plot using columns inside the sampled data
p_rf <- ggplot(rf_sample, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.2, color = "darkgreen") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Random Forest: Actual vs Predicted Resale Prices (Sampled)",
       x = "Actual Price",
       y = "Predicted Price") +
  theme_minimal()

## save 
print(p_rf)
ggsave("rf_actual_vs_predicted_sampled.png", plot = p_rf, width = 8, height = 6, dpi = 300)




```


